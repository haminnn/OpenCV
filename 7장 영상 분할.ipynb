{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bdc8528-90f4-4d47-80b5-719c2ed4d852",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 영상 분할"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572bda88-6df5-4d45-ad87-a9d4a77245ac",
   "metadata": {},
   "source": [
    "1. 영상 분할은 입력 영상에서 관심 있는 영역을 분리하는 과정이다.\n",
    "2. 이러한 영상 분할은 영상분석, 물체 인식, 추적 등 대부분의 영상처리 응용에서 필수적인 단계이다.\n",
    "3. 영상 분할은 크게 경계선 또는 영역으로 분할한다.\n",
    "4. 임계값 사용 방법은 가장 간단한 영상 분할 방법으로 5장에서 cv2.threshold(), cv2.adaptiveThreshold()를 이미 설명하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0ddfcb-95f9-4e0c-bfc6-53fa71db19e1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Canny 에지 검출"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18088ad3-5e1d-4a90-bec7-58e45c5957f5",
   "metadata": {},
   "source": [
    "1. 에지는 영상의 물체와 물체 사이 또는 물체와 배경사이의 테두리에서 발생한다.\n",
    "2. 6장의 1차 미분 필터 cv2.Sobel()와 2차 미분 필터 cv2.Laplacian() 또는 LoG로 필터링한 후에 0-교차점을 찾아 에지를 검출할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52efa66-b0e9-4964-8e69-4331d9b6ab70",
   "metadata": {},
   "source": [
    "- cv2.Canny(image, threshold1, threshold2[, edges[, apertureSize[, L2gradient ]]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d689873-b600-4a5f-8793-bf16d48bd704",
   "metadata": {},
   "source": [
    "##### 1-채널 8비트 입력 영상 image에서 에지를 검출하여 edges를 반환한다.\n",
    "##### apertureSize는 그래디언트를 계산하기 위한 Sobel 필터의 크기로 사용하고, 히스테리시스 임계값에 사용되는 두 임계값 threshold1, threshold2를 사용하여 연결된 에지를 얻는다.\n",
    "##### 먼저 높은 값의 임계값을 사용하여 그래디언트 방향에서 낮은 값의 임계값이 나올 때까지 추적하며 에지를 연결하는 히스테리시스 임계값 방식을 사용한다.\n",
    "##### L2gradient = True이면 그래디언트의 크기를 √((dI/dx)²+(dI/dy)²)로 계산하고, L2gradient = False이면 그래디언트의 크기를 |dI/dx|+|dI/dy|로 계산한다.\n",
    "##### 입력 영상에 cv2.Canny()함수 호출전에 cv2.GaussianBlur()함수 같은 블러링 함수로 영상을 부드럽게 하면 잡음에 덜 민감할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2edf0d-934b-4bf3-8a77-85c7718e7326",
   "metadata": {},
   "source": [
    "#### 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1239e98-02c1-49e8-9b45-68af4b50f4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 에지 검출: cv2.Canny()\n",
    "# 0701.py\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "src = cv2.imread('./data/lena.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "edges1 = cv2.Canny(src, 50, 100) # 입력 영상 src에서 threshold1 = 50, threshold2 = 100, apertureSize = 3으로 Canny 에지를 edges1에 검출한다.\n",
    "edges2 = cv2.Canny(src, 50, 200) # 입력 영상 src에서 threshold1 = 50, threshold2 = 200, apertureSize = 3으로 Canny 에지를 edges2에 검출한다.\n",
    " \n",
    "cv2.imshow('edges1',  edges1)\n",
    "cv2.imshow('edges2',  edges2)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431900f9-b220-48a0-9bf7-33be72652c24",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Hough 변환에 의한 직선 및 원 검출"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127a216f-841c-4c08-b29f-ea448a7227c0",
   "metadata": {},
   "source": [
    "1. Sobel, LoG, Canny로 검출한 에지는 단순히 화소들의 집합니다. 즉, 에지는 직선, 사각형, 원, 곡선 등의 구조적 정보를 갖지 않는다.\n",
    "2. Hough 변환을 사용하면 에지에서 직선 또는 원의 방정식의 파라미터를 검출할 수 있다.\n",
    "3. 직선 검출을 위한 퍼르 변환 알고리즘은 각 에지 점 (x, y)에 대하여, 이산 격자 간격에서 점(x, y)를 지나가는 가능한 모든 직선의 방정식의 파라미터(ρx,θh)를 계산하여, 대응하는 어큐뮬레이터 정수 배열을 1씩 증가시킨다.\n",
    "4. 모든 에지점을 이처럼 처리하면 A(k,h)에는 (ρx,θh)인 직선 위에 있는 에지의 개수가 누적된다. A(k, h) > threshold인 모든(k, h)중에서 지역 극값인 직선을 찾는다.\n",
    "5. 배열 A(k, h)의 각 위치는 하나의 직선의 방정식 ρx = xcos(θh) + ysin(θh)을 표현한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f57d43-e7f3-478c-a838-eaaf37a5ae14",
   "metadata": {},
   "source": [
    "- cv2.HoughLines(image, tho, theta, threshold[, lines[, srn[, stn[, min_theta ]]]]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765e5e54-cf49-4996-8966-ec70db910ea5",
   "metadata": {},
   "source": [
    "##### 1-채널 8비트 이진영상 image에서 직선을 lines에 검출한다.\n",
    "##### lines는 검충된 직선의 (ρ,θ)가 저장된 배열이다. rho는 원점으로부터의 거리 간격, theta는 x축과의 각도로 라디안 간격, threshold는 직선을 검출하기 위한 어큐뮬레이터의 임계값이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b15fe5-de5c-4004-952e-8c4dc3201426",
   "metadata": {},
   "source": [
    "- cv2.HoughLinesP(image, tho, theta, threshold[, lines[, minLineLength[, maxLineGap ]]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a6ce71-661d-4b42-86c1-0d789848d958",
   "metadata": {},
   "source": [
    "##### probabilistic Hough 변환을 이용하여 양 끝점이 있는 선분을 lines에 검출한다.\n",
    "##### 출력 lines는 선분의 양 끝점(x1, x1, x2, y2)를 저장하는 배열이다. rho는 원점으로부터의 거리 간격, theta는 x축과의 각도로 라디안 간격, threshold는 직선을 검출하기 위한 어큐뮬레이터의 임계값이다.\n",
    "##### minLineLength는 검출한 최소 직선의 길이이고, maxLineGap은 직선 위의 에지들의 최대 허용 간격이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cd2c18-f842-4449-a2c5-5ce6ccc7f741",
   "metadata": {},
   "source": [
    "- cv2.HoughCircles(image, method, dp, minDise[, circles[, param1[, param2[, minnRadius[, maxRadius ]]]]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90057e68-d4b9-430c-91b0-5453182cbaef",
   "metadata": {},
   "source": [
    "##### 1채널 8비트 그레이스케일 영상(에지가 아니다) image에서 원을 찾아, 원의 매개변수 (cx, cy, r)를 저장한 배열 circles를 반환한다.\n",
    "##### 현재는 method = cv2.HOUGH_GRADIENT 방법만이 구현되어 있다. dp는 어큐뮬레이터 간격에서 영상 간격으로의 역 비율이다.\n",
    "##### dp = 1이면 어큐뮬레이터가 입력 영상과 같은 해상도를 갖고, dp = 2이면 어큐뮬레이터의 크기가 영상 가로크기의 반, 세로 크기의 반을 의미한다.\n",
    "##### minDist는 검출된 원의 중심 사이의 최소 거리로 너무 작으면 실제 원 주위에 너무 많은 원이 검출되고, 너무 크면 검출하지 못하는 원이 있을 수 있다.\n",
    "##### param1은 Canny에서 검출의 높은 임계값인 threshold2이다. 낮은 임계값은 threshold1 = param1 / 2이다.\n",
    "##### param2는 원 검출을 위한 어큐뮬레이터의 임계값으로 작은 값이면 너무 많은 원이 검출되고, 너무 크면 찾지 못하는 원이 있을 수 있다.\n",
    "##### minRadius는 원의 최소 반지름, maxRadius는 원의 최대 반지름이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83046f65-5c6f-4686-a8f1-06791b884ad6",
   "metadata": {},
   "source": [
    "#### 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8068b0db-5990-47cd-b042-cd5f0ba2e46c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lines.shape= (4, 1, 2)\n"
     ]
    }
   ],
   "source": [
    "## 직선검출:cv2.HoughLines()\n",
    "# 0702.py\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "src = cv2.imread('./data/rect.jpg')\n",
    "gray = cv2.cvtColor(src,cv2.COLOR_BGR2GRAY)\n",
    "edges = cv2.Canny(gray, 50, 100)\n",
    "lines = cv2.HoughLines(edges, rho=1, theta=np.pi/180.0, threshold=100) # cv2.HoughLines()로 rho = 1, theta = np.pi / 180.0, threshold = 100을 \n",
    "                                                                       # 적용하여 선분을 lines에 검출한다. 검출된 직선의 rho, theta를 저장한\n",
    "                                                                       # lines의 배열의 모양은 line.shape = (4, 1, 2)이다.\n",
    "                                                                       # 4개의 직선의 rho, theta를 저장한 (1, 2)로 이해하면 된다.\n",
    "print('lines.shape=', lines.shape)\n",
    "\n",
    "for line in lines:\n",
    "    rho, theta   = line[0]\n",
    "    c = np.cos(theta)\n",
    "    s = np.sin(theta)\n",
    "    x0 = c*rho\n",
    "    y0 = s*rho\n",
    "    x1 = int(x0 + 1000*(-s))\n",
    "    y1 = int(y0 + 1000*(c))\n",
    "    x2 = int(x0 - 1000*(-s))\n",
    "    y2 = int(y0 - 1000*(c))\n",
    "    cv2.line(src, (x1, y1), (x2, y2), (0,0,255), 2)\n",
    "    \n",
    "# for 문에서 각 직선의 매개변수는 rho, theta = line[0]이고, rho, theta를 이용하여 검출된 직선을 그린다. 원점에서 (rho, theta)에 의한 직선과 직각으로\n",
    "# 만나는 좌표(x0, y0)는 x0 = rho *c, y0 = rho * s로 계산한다. 직선 방향으로의 단위 벡터는 (cos(theta), -sin(theta))이다.\n",
    "# 이 단위 벡터를 +, -방향으로 스케일링하고, x0, y0에 더하여 선분의 양 끝점 (x1, y1)과 (x2, y2)를 계산하여 cv2.line()으로 src에 직선을 그리면 그림과 같이 4개의 직선이 표시된다.\n",
    "    \n",
    "cv2.imshow('edges',  edges)\n",
    "cv2.imshow('src',  src)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13ae8280-70f8-408c-837f-5a2e3c9043d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lines.shape= (4, 1, 4)\n"
     ]
    }
   ],
   "source": [
    "## 선분 검출: cv2.HoughLinesP()\n",
    "# 0703.py\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "src = cv2.imread('./data/rect.jpg')\n",
    "gray = cv2.cvtColor(src,cv2.COLOR_BGR2GRAY)\n",
    "edges = cv2.Canny(gray, 50, 100)\n",
    "lines = cv2.HoughLinesP(edges, rho=1, theta=np.pi/180.0, threshold=100) # cv2.HoughLinesP()로 rho = 1, theta = np.pi / 180.0, threshold = 100을\n",
    "                                                                        # 적용하여 선분을 lines에 검출한다. 검출된 선분의 양 끝점(x1, y1, x2, y2)을\n",
    "                                                                        # 저장한 lines 배열의 모양은 lines.shape = (4, 1, 4)이다. 4개의 선분의양 끝점을 저장한 (1, 4)로 이해하면 된다.\n",
    "print('lines.shape=', lines.shape)\n",
    "\n",
    "for line in lines:\n",
    "    x1, y1, x2, y2   = line[0]\n",
    "    cv2.line(src,(x1,y1),(x2,y2),(0,0,255),2)\n",
    "    \n",
    "cv2.imshow('edges',  edges)\n",
    "cv2.imshow('src',  src)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "72ff0654-7f03-4426-b3a1-aac651bb0e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "circles1.shape= (1, 3, 3)\n",
      "circles2.shape= (1, 6, 3)\n"
     ]
    }
   ],
   "source": [
    "# 0704.py\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "#1\n",
    "src1 = cv2.imread('./data/circles.jpg')\n",
    "gray1 = cv2.cvtColor(src1,cv2.COLOR_BGR2GRAY)\n",
    "circles1 = cv2.HoughCircles(gray1, method = cv2.HOUGH_GRADIENT,\n",
    "            dp=1, minDist=50, param2 = 15)\n",
    "\n",
    "circles1 =  np.int32(circles1)\n",
    "print('circles1.shape=', circles1.shape)\n",
    "for circle in circles1[0,:]:    \n",
    "    cx, cy, r  = circle\n",
    "    cv2.circle(src1, (cx, cy), r, (0,0,255), 2)\n",
    "cv2.imshow('src1',  src1)\n",
    "\n",
    "# 'circles.jpg'의 그레이스케일 영상 gray1에서, cv2.HoughCircles()로 method = cv2.HOUGH_GRADIENT, dp = 1, minDist = 50, param2 = 15를 적용하여\n",
    "# circles1에 원을 검출한다. param2 = 15는 원 검출을 위한 어큐뮬레이터의 임계값으로 원 위의 에지 개수이다. 검출된 원의 중심 cx, cy, 반지름 r을 저장한\n",
    "# circles1 배열은 circles1.shape = (1, 3, 3)으로 circles1[0]의 3개의 행에 원의 cx, cy, r을 저장한다.\n",
    "\n",
    "#2\n",
    "src2 = cv2.imread('./data/circles2.jpg')\n",
    "gray2 = cv2.cvtColor(src2,cv2.COLOR_BGR2GRAY)\n",
    "circles2 = cv2.HoughCircles(gray2, method = cv2.HOUGH_GRADIENT,\n",
    "          dp=1, minDist=50, param2=15, minRadius=30, maxRadius=100)\n",
    "\n",
    "# 'circle.jpg'의 그레이스케일 영상 gray2에서, cv2.HoughCircle()로 method = cv2.HOUGH_GRADIENT, dp = 1, minDist = 50, param2 = 15, minRadius = 30,\n",
    "# maxRadius = 100을 적용하여 circle2에 원을 검출한다. 원의 반지름의 범위를 minRadius = 30, maxRadius = 100으로 제한하여 원을 검출한다.\n",
    "# circles2 배열은 circles2.shape = (1, 6, 3)으로 circles[0]의 6개의 행에 원의 cx, cy, r을 저장한다.\n",
    "\n",
    "circles2 =  np.int32(circles2)\n",
    "print('circles2.shape=', circles2.shape)\n",
    "for circle in circles2[0,:]:    \n",
    "    cx, cy, r  = circle\n",
    "    cv2.circle(src2, (cx, cy), r, (0,0,255), 2) \n",
    "cv2.imshow('src2',  src2)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf18d8f-5547-401b-999f-09ec2a432046",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 컬러 범위에 의한 영역 분할"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738d86c8-79e8-4fbf-8e03-7683faac41a8",
   "metadata": {},
   "source": [
    "- cv2.inRange(src, lowerb, upperb[, dst ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696031dd-c0bd-494e-b00a-f9b876e8aae9",
   "metadata": {},
   "source": [
    "##### 입력 src의 각 화소가 lowerb(i) <= src(i) <= upperb(i) 범위에 있으면, dst(i) = 255, 그렇지 않으면 dst(i) = 0이다.\n",
    "##### lowerb와 upperb는 Scalar도 가능하고, dst는 src와 같은 크기의 8비트 부호없는 정수 자료형이다. src가 다중 채널인 경우, 모든 채널에 대하여 범위를 만족해야 한다.\n",
    "##### 3-채널 컬러 영상에서, HSV 색상으로 변환한 후에, 색상 범위를 지정하여 손, 얼굴 등의 피부 검출 등을 분할할 때 유용하다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931c5861-b70f-48c9-9103-24c4ed972c93",
   "metadata": {},
   "source": [
    "#### 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "533df0bb-4db9-4838-b382-e09a8acd174d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 컬러 영역 검출: cv2.inRange()\n",
    "# 0705.py\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "#1\n",
    "src1 = cv2.imread('./data/hand.jpg')\n",
    "hsv1 = cv2.cvtColor(src1, cv2.COLOR_BGR2HSV)\n",
    "lowerb1 = (0, 40, 0)\n",
    "upperb1 = (20, 180, 255)\n",
    "dst1 = cv2.inRange(hsv1, lowerb1, upperb1)   # 'hand.jpg'영상을 3-채널 BGR 컬러 영상으로 읽은 src1을 HSV영상으로 hsv1에 변환하고, hsv1에서 cv2.inRange()로\n",
    "                                             # lowerb1 = (0, 40, 0), upperb1 = (20, 180, 255) 범위를 적용하여 손영역을 분할한다.\n",
    "\n",
    "#2\n",
    "src2 = cv2.imread('./data/flower.jpg')\n",
    "hsv2 = cv2.cvtColor(src2,cv2.COLOR_BGR2HSV)\n",
    "lowerb2 = (150, 100, 100)\n",
    "upperb2 = (180, 255, 255)\n",
    "dst2 = cv2.inRange(hsv2, lowerb2, upperb2)   # 'flower.jpg'영상을 3-채널 BGR 컬러 영상으로 읽은 src2를 HSV영상으로 hsv2에 변환하고, hsv2에서 cv2.inRange()로\n",
    "                                             # lowerb2, = (150, 100, 100), upperb2 = (180, 255, 255) 범위를 적용하여 꽃 영역을 분할한다.\n",
    "\n",
    "#3\n",
    "cv2.imshow('src1',  src1)\n",
    "cv2.imshow('dst1',  dst1)\n",
    "cv2.imshow('src2',  src2)\n",
    "cv2.imshow('dst2',  dst2)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834437af-6809-409e-997a-e7b2eadd3245",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 윤곽선 검출 및 그리기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f259d131-671c-47f2-a303-f07d1ca3ecd8",
   "metadata": {},
   "source": [
    "1. 윤곽선을 검출하고 그리기 기능을 수행 함수로는 물체의 경계를 이루고 있는 윤곽선을 검출하는 findContours() 함수와 검출된 윤곽선을 영상에 그리는 drawContours()함수가 있다.\n",
    "2. 입력 영상은 cv2.inRange(), cv2.threshold(), cv2.Canny() 등을 사용하여 얻은 이진 영상이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86fac26-b2fd-4cac-9d99-cfe749538ec3",
   "metadata": {},
   "source": [
    "- cv2.findContours(image, mode, method[, contours[, hierarchy[, offset ]]]) -> contours, hierarchy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322917f5-2485-468b-b94b-1e34320c983f",
   "metadata": {},
   "source": [
    "##### 1-채널 8비트 영상 image에서 윤곽선을 검출한다. image는 0이 아닌 값은 1로 취급하는 영상이다.\n",
    "##### contours는 검출된 윤곽선이고, 리스트 자료형의 각 요소에 윤곽선을 배열로 반환한다.\n",
    "##### hierarchy는 윤곽선의 계층 구조에 관한 출력 배열이다. hierarchy[0][i]는 윤곽선 contour[i]에 대한 계층 구조의 배열이다.\n",
    "##### hierarchy[0][i][0]과 hierarchy[0][i][1]은 같은 계층 구조 에벨에서 다음과 이전 윤곽선이다. hierarchy[0][i][2]와 hierarchy[0][i][3]은 첫 번째 자식과 부모 윤곽선이다. 대응하는 윤곽선이 없으면 음수 값을 갖는다.\n",
    "##### mode는 윤곽선의 검색모드로 사용 가능한 mode는 cv2.RETR_EXTERMAL, cv2.RETR_LIST, cv2.RETR_CCOMP, cv2.RETR_TREE이다.\n",
    "##### method는 윤곽선의 근사 방법으로 사용 가능한 method는 cv2.CHAIN_APPROX_NONE, cv2.CHAIN_APPROX_SIMPLE, cv2.CHAIN_APPROX_TC89_L1, cv2.CHAIN_APPROX_TC89_KCOS이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400742f0-1c4f-4137-8c09-c8a1652e86f5",
   "metadata": {},
   "source": [
    "- cv2.drawContours(image, contours, contourIdx, color[, thickness[, lineType[, hierarchy[, maxLevel[, offset ]]]]]) -> image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9554a39d-4962-4245-9722-50381306323d",
   "metadata": {},
   "source": [
    "##### 영상 image에 윤곽선 리스트 contours를 color 색상으로 그린다. 각각의 윤곽선 contour는 좌표 배열이다.\n",
    "##### contourIdx는 표시할 윤곽선 첨자로 contourIdx < 0 이면 모든 윤곽선을 그린다.\n",
    "##### thickness는 윤곽선의 두께이며, thickness = cv2.FILLED(-1)이면 윤곽선 내부를 채운다.\n",
    "##### lineType은 라인의 형태로 8, 4, CV_AA 중 하나이다.\n",
    "##### hierarchy는 윤곽선의 계층 구조로 maxLevel에 의해 주어진 계층 구조를 그릴 때 사용된다.\n",
    "##### maxLevel = 0이면 명시된 contour만을 그리고, maxLebel = 1이면 contour를 그린 뒤에 contour에 내포된 윤곽선을 그린다.\n",
    "##### offset에 주어진 좌표만큼 윤곽선의 모든 좌표를 이동시킨다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c67f9ac-7770-41e9-95e9-88dd27bea8fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(contours)= <class 'tuple'>\n",
      "type(contours[0])= <class 'numpy.ndarray'>\n",
      "len(contours)= 1\n",
      "contours[0].shape= (4, 1, 2)\n",
      "contours[0]= [[[ 50 100]]\n",
      "\n",
      " [[ 50 400]]\n",
      "\n",
      " [[450 400]]\n",
      "\n",
      " [[450 100]]]\n"
     ]
    }
   ],
   "source": [
    "## 윤곽선 검출 및 그리기 1: mode = cv2.RETR_EXTERNAL\n",
    "# 0706.py\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "#1\n",
    "src = np.zeros(shape=(512,512,3), dtype=np.uint8)\n",
    "cv2.rectangle(src, (50, 100), (450, 400), (255, 255, 255), -1)\n",
    "cv2.rectangle(src, (100, 150), (400, 350), (0, 0, 0), -1)\n",
    "cv2.rectangle(src, (200, 200), (300, 300), (255, 255, 255), -1)\n",
    "gray = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)\n",
    "# src에 512 x 512크기의 3-채널 컬러영상을 생성하고, cv2.rectangle()로 채워진 사각형을 그린다.\n",
    "# cv2.cvtColor()로 그레이스케일 영상 gray으로 변환한다.\n",
    "\n",
    "#2\n",
    "mode = cv2.RETR_EXTERNAL\n",
    "method = cv2.CHAIN_APPROX_SIMPLE\n",
    "## method =cv2.CHAIN_APPROX_NONE\n",
    "contours, hierarchy = cv2.findContours(gray, mode, method)\n",
    "# cv2.findContours()로 윤곽선 contours를 검출한다. \n",
    "# mode = cv2.RETR_EXTERNAL로 리스트 contours에 len(contours) = 1개의 가장 외각의 윤곽선을 검출한다.\n",
    "# method = cv2.CHAIN_APPROX_SIMPLE로 윤곽선을 다각형으로 근사한 과표를 반환한다. contours[0].shape = (4, 1, 2)은 4개의 검출된 좌표가 (1, 2) 배열에 저장된다.\n",
    "# method = cv2.CHAIN_APPROX_NONE이면, contours[0].shape = (1400, 1, 2)로 윤곽선위의 모든 좌표 1400개를 검출한다.\n",
    "\n",
    "print('type(contours)=', type(contours))\n",
    "print('type(contours[0])=', type(contours[0]))\n",
    "print('len(contours)=', len(contours))\n",
    "print('contours[0].shape=', contours[0].shape)\n",
    "print('contours[0]=', contours[0])\n",
    "\n",
    "#3\n",
    "cv2.drawContours(src, contours, -1, (255,0,0), 3) # contourIdx < 0 이면 모든 윤곽선을 그리는데 -1이기때문에 모든 윤곽선을 그린다.\n",
    "# cv2.drawContours(src, contours, -1, (255, 0, 0), 3)는 검출된 윤곽선 contours를 전부를 src(255, 0, 0) 컬러로 두께 3으로 그린다.\n",
    "\n",
    "#4\n",
    "for pt in contours[0][:]: \n",
    "    cv2.circle(src, (pt[0][0], pt[0][1]), 5, (0,0,255), -1)\n",
    "# for문으로 윤곽선의 (1, 2)좌표 배열 pt에 의해 중심점(pt[0][0], pt[0][1]), 반지름 5인 (0, 0, 255) 컬러로 채워진 원을 src에 그린다.\n",
    "    \n",
    "cv2.imshow('src',  src)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e3e25d17-734c-4ec2-b8ec-756bd6f51037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(contours)= 3\n",
      "contours[0].shape= (4, 1, 2)\n",
      "contours= (array([[[200, 200]],\n",
      "\n",
      "       [[200, 300]],\n",
      "\n",
      "       [[300, 300]],\n",
      "\n",
      "       [[300, 200]]], dtype=int32), array([[[ 99, 150]],\n",
      "\n",
      "       [[100, 149]],\n",
      "\n",
      "       [[400, 149]],\n",
      "\n",
      "       [[401, 150]],\n",
      "\n",
      "       [[401, 350]],\n",
      "\n",
      "       [[400, 351]],\n",
      "\n",
      "       [[100, 351]],\n",
      "\n",
      "       [[ 99, 350]]], dtype=int32), array([[[ 50, 100]],\n",
      "\n",
      "       [[ 50, 400]],\n",
      "\n",
      "       [[450, 400]],\n",
      "\n",
      "       [[450, 100]]], dtype=int32))\n"
     ]
    }
   ],
   "source": [
    "## 윤곽선 검출 및 그리기 2: mode = cv2.RETR_LIST\n",
    "# 0707.py\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "#1\n",
    "src = np.zeros(shape=(512,512,3), dtype=np.uint8)\n",
    "cv2.rectangle(src, (50, 100), (450, 400), (255, 255, 255), -1)\n",
    "cv2.rectangle(src, (100, 150), (400, 350), (0, 0, 0), -1)\n",
    "cv2.rectangle(src, (200, 200), (300, 300), (255, 255, 255), -1)\n",
    "gray = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)\n",
    "# src에 512 x 512 크기의 3-채널 컬러 영상을 생성하고, cv2.rectangle()로 채워진 사각형을 그린다.\n",
    "# cv2.cvtColor()로 그레이스케일 영상 gray으로 변환한다.\n",
    "\n",
    "#2\n",
    "mode = cv2.RETR_LIST\n",
    "method = cv2.CHAIN_APPROX_SIMPLE;\n",
    "contours, hierarchy = cv2.findContours(gray, mode, method)\n",
    "# cv2.drawContours(src, contours, -1, (255,0,0), 3)  \n",
    "# cv2.findContours()로 윤곽선 contours를 검출한다. mode = cv2.RETR_LIST로 리스트 contours에 len(contours) = 3개의 모든 윤곽선을 검출한다.\n",
    "# method = cv2.contours[0]은 contours[0].shape = (4, 1, 2)로 4개의 검출된 좌표가 (1, 2) 배열에 저장된다.\n",
    "# cv2.drawContours(src, contours, -1, (255, 0, 0), 3)는 리스트 contours의 모든 윤곽선을 그린다.\n",
    "\n",
    "print('len(contours)=', len(contours))\n",
    "print('contours[0].shape=', contours[0].shape)\n",
    "print('contours=', contours)\n",
    "\n",
    "#3\n",
    "for cnt in contours:\n",
    "    cv2.drawContours(src, [cnt], 0, (255,0,0), 3)\n",
    "    \n",
    "    for pt in cnt: \n",
    "        cv2.circle(src, (pt[0][0], pt[0][1]), 5, (0,0,255), -1)\n",
    "# for 문으로 리스트 contours의 각 윤곽선 cnt를 cv2.drawContours(src, [cnt], 0, (255, 0, 0), 3)로 그리고, for문으로 cnt의 각 좌표pt가 중심인 반지름 5의 원을\n",
    "# (0, 0, 255)컬러로 그린다.\n",
    "\n",
    "cv2.imshow('src',  src)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a2d8a4-fc1a-4f12-bd07-98b4272088ae",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 영역 채우기 · 인페인트 · 거리 계산 · 워터쉐드"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa70d2a-6bad-45a1-aa3a-9184c3ab5407",
   "metadata": {},
   "source": [
    "1. cv2.floodFill()은 물체의 내부를 특정 값으로 채우고, cv2.impaint()는 영상에서 부분 영역을 삭제하고 주변의 화소 값을 이용하여 채우며, cv2.distanceTransform()은 영상 영역의 내부의 0이 아닌 화소에서, 가장 가까운 0인 화소까지의 거리를 계산한다.\n",
    "2. cv2.watershed()는 마커 기반 영상 분할을 수행한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da80ed6-c851-4114-8f98-ad6924043512",
   "metadata": {},
   "source": [
    "- cv2.floodFill(image, mask, seedPoint, newVal[, loDiff[, upDiff[, flags ]]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5700f05-8e8e-4325-a266-13009a953a4b",
   "metadata": {},
   "source": [
    "##### 입력 영상 image에서 seedPoint 점에서 시작하여 물체 내부를 채운다. image가 변경되므로 필요한 경우 원본을 복사해 사용한다.\n",
    "##### falgs에 지정된 이웃(4 또는 8) 화소 (x', y')를 반복적으로 조사해가며 image(x', y') -loDiff <= image(x, y) + upDiff에 있는 (x, y)점을 새로운 값 newVal로 채워 넣는다.\n",
    "##### masks는 8비트 단일 채널이며, 크기는 입력 영상 image보다 가로와 세로 2 만큼씩 크다.\\\n",
    "##### flags에 cv2.FLOODFILL_FIXED_RANGE이 추가되면 현재 화소와 seedPoint 사이의 차이를 고려하여 영역을 채우고, cv2.FLOODFILL_RANGE가 설정되지 않으면 이웃 화소들 사이의 차이를 고려하여 영역을 채운다. cv2.FLOODFILL_MASK_ONLY가 설정되면 image를 채우지 않고 mask를 채운다.\n",
    "##### rect는 채워진 영역의 바운딩 사각형을 반환한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efc11bc-fbba-414f-8ddc-775c107dc8b0",
   "metadata": {},
   "source": [
    "- cv2.distanceTransform(src, distanceType, maskSize[, dst ]) -> dst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a59b1a-23f8-4812-8a73-9500ad015cf5",
   "metadata": {},
   "source": [
    "##### src에서 0이 아닌 화소에서 가장 가까운 화소까지의 거리를 계산하여 실수형 배열 dst에 반환한다.\n",
    "##### src는 1-채널 8비트의 이진 영상이며, dst는 1-채널 32비트 실수형 배열이다.\n",
    "##### distanceType은 cv2.DIST_L1, cv2.DIST_L2, cv2.DIST_C의 거리 계산 종류이다.\n",
    "##### maskSize는 3, 5, cv2.DIST_MASK_PRECISE 마스크 크기가 가능하다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee36fcc-6696-4b9a-9c8c-79e0a662cf3f",
   "metadata": {},
   "source": [
    "- cv2.watershed(image, markers) -> markers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec31a9be-a698-4aec-b950-1787eb620256",
   "metadata": {},
   "source": [
    "##### 마커 기반으로 영상을 분할한다.\n",
    "##### 8비트 3-채널 컬러 영상 image에 사용자가 대략적으로 32비트 정수 1-채널 markers에 부분 영역을 설정하면 영상을 분할하여 markers배열을 반환한다.\n",
    "##### 초기에 markers에 주어진 영역의 값을 씨앗(seed)으로 하여 나머지 영역을 분할한다.\n",
    "##### 반환 배열 markers에 1 이상의 값을 가지며 markers의 값이 같으면 동일 특성을 갖는 분할 영역이며, 영역의 경계 부분은 -1을 갖는다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9ccbbd-2e0c-4e77-a350-4592fee3a2d6",
   "metadata": {},
   "source": [
    "#### 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "673dd461-cc80-4db7-b1a8-48ec28c2c43d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rect= (202, 202, 197, 197)\n"
     ]
    }
   ],
   "source": [
    "## cv2.floodFill() 영역 채우기\n",
    "# 0708.py\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "#1\n",
    "src = np.full((512,512,3), (255, 255, 255), dtype= np.uint8)\n",
    "cv2.rectangle(src, (50, 50), (200, 200), (0, 0, 255), 2)\n",
    "cv2.circle(src, (300, 300), 100, (0,0,255), 2)\n",
    "# 512 x 512 크기의 배경이 (255, 255, 255)인 3-채널 컬러 영상 src를 생성하고 사각형과 원을 그린다.\n",
    "\n",
    "#2\n",
    "dst = src.copy()\n",
    "cv2.floodFill(dst, mask=None, seedPoint=(100,100), newVal=(255,0,0))\n",
    "# src를 dst에 복사하고, cv2.floodFill()로 dst에 seedPoint = (100, 100)을 시작점으로 사각형 내부를 newVal = (255, 0, 0)색상으로 dst에 채운다.\n",
    "\n",
    "#3\n",
    "retval, dst2, mask, rect=cv2.floodFill(dst, mask=None,\n",
    "                          seedPoint=(300,300), newVal=(0,255,0))\n",
    "print('rect=', rect)\n",
    "x, y, width, height = rect\n",
    "cv2.rectangle(dst2, (x,y), (x+width, y+height), (255, 0, 0), 2)\n",
    "# cv2.floodFill()로 dst의 seedPint = (300, 300)를 시작점으로 원의 내부를 newVal =  (0, 255, 0) 색상으로 dst에 채운다.\n",
    "# 원의 내부를 채운 영역의 바운딩 사각형 rect를 이용하여 dst2에 사각형을 그린다.\n",
    "\n",
    "cv2.imshow('src',  src)\n",
    "cv2.imshow('dst',  dst)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e17fab82-a1ae-4f3f-a117-2a006d5b87d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src: 0.0 51.0 (0, 0) (100, 250)\n",
      "src: 0.0 8.0 (0, 0) (52, 200)\n"
     ]
    }
   ],
   "source": [
    "## cv2.distanceTransform() 거리 계산\n",
    "# 0709.py\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "#1\n",
    "src = np.zeros(shape=(512,512), dtype=np.uint8)\n",
    "cv2.rectangle(src, (50, 200), (450, 300), (255, 255, 255), -1)\n",
    "# src에 512 x 512 크기의 그레이스케일 영상을 생성하고, cv2.rectangle()로 채워진 사각형을 그린다.\n",
    "\n",
    "#2\n",
    "dist  = cv2.distanceTransform(src, distanceType=cv2.DIST_L1, maskSize=3)\n",
    "minVal, maxVal, minLoc, maxLoc = cv2.minMaxLoc(dist)\n",
    "print('src:', minVal, maxVal, minLoc, maxLoc)\n",
    "dst = cv2.normalize(dist, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "ret, dst2 = cv2.threshold(dist, maxVal-1, 255, cv2.THRESH_BINARY)\n",
    "# src에 cv2.distanceTransform()로 distanceType = cv2.DIST_L1, maskSize = 3를 적용하여 dist에 거리를 계산한다.\n",
    "# cv2.minMaxLoc(dist)로 계산한 최대값은 maxVal = 51.0이다.\n",
    "# cv2.normalize()로 dist를 [0, 255]범위로 정규화한다.\n",
    "# cv2.threshold()로 dist를 thresh = maxVal - 1로 dst2에 임계값을 적용한다.\n",
    "\n",
    "#3 \n",
    "gx = cv2.Sobel(dist, cv2.CV_32F, 1, 0, ksize = 3)\n",
    "gy = cv2.Sobel(dist, cv2.CV_32F, 0, 1, ksize = 3)\n",
    "mag   = cv2.magnitude(gx, gy)\n",
    "minVal, maxVal, minLoc, maxLoc = cv2.minMaxLoc(mag)\n",
    "print('src:', minVal, maxVal, minLoc, maxLoc)\n",
    "ret, dst3 = cv2.threshold(mag, maxVal-2, 255, cv2.THRESH_BINARY_INV)\n",
    "# cv2.Sobel()로 거리 dist에서 그래디언트를 계산하고, 크기 mag를 계산하여 thresh = maxVal - 2, cv2.THRESH_BINARY_INV으로 임계값 영상을 생성\n",
    "\n",
    "cv2.imshow('src',  src)\n",
    "cv2.imshow('dst',  dst)\n",
    "cv2.imshow('dst2',  dst2)\n",
    "cv2.imshow('dst3',  dst3)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "732e4013-3fce-47db-8a3c-535147bbbf8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(contours)= 9\n",
      "len(contours)= 1\n",
      "len(contours)= 0\n"
     ]
    }
   ],
   "source": [
    "## cv2.watershed() 영상 분할\n",
    "# 0710.py\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "#1\n",
    "# src = cv2.imread('./data/hand.jpg')\n",
    "src = cv2.imread('./data/flower.jpg')\n",
    "mask   = np.zeros(shape=src.shape[:2], dtype=np.uint8)\n",
    "markers= np.zeros(shape=src.shape[:2], dtype=np.int32)\n",
    "dst = src.copy()\n",
    "cv2.imshow('dst',dst)\n",
    "# src는 입력 영상이고 마우스로 지정할 마스크 영역을 지정하고, 윤곽선을 검출한 mask 영상, 윤곽선을 이용하여 워터쉐드 분할을 위한 마커 영상 markers를 생성한다.\n",
    "\n",
    "\n",
    "#2\n",
    "def onMouse(event, x, y, flags, param):\n",
    "    if event == cv2.EVENT_MOUSEMOVE:\n",
    "        if flags & cv2.EVENT_FLAG_LBUTTON:\n",
    "            cv2.circle(param[0], (x, y), 10, (255, 255, 255), -1)\n",
    "            cv2.circle(param[1], (x, y), 10, (255, 255, 255), -1) \n",
    "    cv2.imshow('dst', param[1])    \n",
    "##cv2.setMouseCallback('dst', onMouse, [mask, dst])\n",
    "# 마우스 이벤트 핸들러 함수 onMouse()를 정의한다. param[0]은 mask, param[1]은 dst가 전달된다.\n",
    "# 마우스 왼쪽버튼을 누르고 움직이면 param[0], param[1]에 반지름이 20인 채운 원을 그린다.\n",
    "\n",
    "#3\n",
    "mode = cv2.RETR_EXTERNAL\n",
    "method = cv2.CHAIN_APPROX_SIMPLE\n",
    "\n",
    "while True:\n",
    "    cv2.setMouseCallback('dst', onMouse, [mask, dst]) #3-1\n",
    "    \n",
    "    key = cv2.waitKey(30) # cv2.waitKeyEx(30)\n",
    "    \n",
    "    if key == 0x1B: \n",
    "        break;\n",
    "        # ESC키를 누르면 반복문 탈출\n",
    "        \n",
    "    elif key == ord('r'): #3-2\n",
    "        mask[:,:] = 0        \n",
    "        dst = src.copy()\n",
    "        cv2.imshow('dst',dst)        \n",
    "        # 'r'키를 누르면 리셋하기 위하며 mask의 모든 화소를 0으로 초기화하고, src를 dst에 복사하고 'dst' 윈도우에 표시한다.\n",
    "        \n",
    "    elif key == ord(' '): #3-3\n",
    "        contours, hierarchy = cv2.findContours(mask, mode, method)\n",
    "        print('len(contours)=', len(contours))\n",
    "        markers[:,:] = 0  \n",
    "        for i, cnt in enumerate(contours):\n",
    "            cv2.drawContours(markers, [cnt], 0, i+1, -1)\n",
    "        cv2.watershed(src,  markers)\n",
    "        # 'space bar'키를 누르면, mask에 윤곽선을 검출하고, markers를 0으로 초기화하고, cv2.drawContours()로 markers에 윤곽선 contours[i]를 i + 1값으로\n",
    "        # 채워 넣어, cv2.watershed()의 입력으로 사용한다. cv2.watershed()로 src에서 markers에 표시된 마커 정보를 이용하여 영역을 markers에 분할한다.\n",
    "        \n",
    "        #3-4        \n",
    "        dst = src.copy()\n",
    "        dst[markers == -1] = [0,0,255] # 경계선\n",
    "        for i in range(len(contours)): # 분할영역 \n",
    "            r = np.random.randint(256)\n",
    "            g = np.random.randint(256)\n",
    "            b = np.random.randint(256)\n",
    "            dst[markers == i+1] = [b, g, r]\n",
    "            # src를 dst에 복사하고, dst[markers == -1] = [0, 0, 255]에 의해 markers에 -1인 경계선을 빨간색 [0, 0, 255]로 변경한다.\n",
    "            # for 문에서 r, g, b에 [0, 255] 사이의 난수를 생성하여 dst[markers == i+1] = [b, g, r]로 markers == i + 1인 dst의 화소를 [b, g, r] 컬러로 변경한다.\n",
    "\n",
    "        dst = cv2.addWeighted(src, 0.4, dst, 0.6, 0) # src * 0.4 와 dst * 0.6으로 섞어 dst에 저장하고, 'dst'윈도우에 표시한다.\n",
    "        cv2.imshow('dst',dst)\n",
    "        \n",
    "        \n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d9f62c6f-0053-4640-9489-9d3b9a126133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dist: 0.0 76.0 (0, 0) (220, 220)\n",
      "len(contours)= 6\n"
     ]
    }
   ],
   "source": [
    "## cv2.distanceTransform(), cv2.watershed() 영상 분할\n",
    "# 0711.py\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "#1\n",
    "src = cv2.imread('./data/circles2.jpg')\n",
    "gray = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)\n",
    "ret, bImage = cv2.threshold(gray, 0, 255,\n",
    "                                cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "dist  = cv2.distanceTransform(bImage, cv2.DIST_L1, 3)\n",
    "dist8 = cv2.normalize(dist, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "\n",
    "cv2.imshow('bImage',bImage)\n",
    "cv2.imshow('dist8',dist8)\n",
    "# 입력 영상 src를 그레이스케일 영상 gray로 변환하고, threshold()로 임계값을 이용하여 이진 영상 bImage를 생성한다.\n",
    "# cv2.distanceTransform()로 bImage에서 거리배열 dist를 계산한다.\n",
    "# 거리를 보여주기 위해 8비트 영상으로 dist8에 정규화한다.\n",
    "\n",
    "#2\n",
    "minVal, maxVal, minLoc, maxLoc = cv2.minMaxLoc(dist)\n",
    "print('dist:', minVal, maxVal, minLoc, maxLoc)\n",
    "mask = (dist > maxVal*0.5).astype(np.uint8)*255\n",
    "cv2.imshow('mask',mask)\n",
    "# mask = (dist > maxVal * 0.5)로 거리 dist에서 최대값 maxVal를 이용하여 8비트 mask 영상을 계산한다. dist대신 dist8을 이용할 수 있다.\n",
    "# 여기서 중요한 점은 이진 영상 bImage에서 겹쳐진 원이 거리 계산을 이용한 mask에서는 분리된 것을 알 수 있다.\n",
    "# 이렇게 분리하기 위하여 cv2.distanceTransform()을 이용한 것이다.\n",
    "\n",
    "#3\n",
    "mode = cv2.RETR_EXTERNAL\n",
    "method = cv2.CHAIN_APPROX_SIMPLE\n",
    "contours, hierarchy = cv2.findContours(mask, mode, method)\n",
    "print('len(contours)=', len(contours))\n",
    "\n",
    "markers= np.zeros(shape=src.shape[:2], dtype=np.int32)\n",
    "for i, cnt in enumerate(contours):\n",
    "    cv2.drawContours(markers, [cnt], 0, i+1, -1)\n",
    "# cv2.findContours()로 mask에서 윤곽선 contours를 검출한다.\n",
    "# 윤곽선 contours[i]를 markers에 i + 1로 채워 마커를 생성하여, cv2.watershed()로 src에서 markers에 표시된 마커 정보를 이용하여 영역을 markers에 분할한다.\n",
    "\n",
    "#4\n",
    "dst = src.copy()\n",
    "cv2.watershed(src,  markers)\n",
    "\n",
    "dst[markers == -1] = [0, 0, 255] # 경계선\n",
    "for i in range(len(contours)): # 분할영역\n",
    "    r = np.random.randint(256)\n",
    "    g = np.random.randint(256)\n",
    "    b = np.random.randint(256)\n",
    "    dst[markers == i+1] = [b, g, r]\n",
    "dst = cv2.addWeighted(src, 0.4, dst, 0.6, 0) # 합성        \n",
    "# src를 dst에 복사하고, dst[markers == -1] = [0, 0, 255]에 의해 markers에 -1인 경계선을 빨간색 [0, 0, 255]로 변경한다.\n",
    "# for 문에서 r, g, b에 [0, 255] 사이의 난수를 생성하여 dst[markers == i + 1]인 dst의 화소를 [b, g, r]컬러로 변경한다.\n",
    "# cv2.addWeighted()로 src * 0.4와 dst * 0.6으로 섞어 dst에 저장\n",
    "\n",
    "cv2.imshow('dst',dst)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fd915f-acd3-4a36-a887-6a5accc15350",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 피라미드 기반 분할"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff578c6-6872-4a23-9b2b-77675b85106a",
   "metadata": {},
   "source": [
    "- cv2.pyrDown(src[, dst[, dstsize[, borderType ]]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7442d926-2c07-4066-918c-f6f8364ab03d",
   "metadata": {},
   "source": [
    "##### 영상 src에 가우시안 필터링하고, dstsize에 주어진 크기로 dst에 축소한다.\n",
    "##### default는 가로, 세로 각각을 1/2배 크기로 축소한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80792a83-273c-4052-adcf-b9c7793fe81c",
   "metadata": {},
   "source": [
    "- cv2.pyrUp(src[, dst[, dstsize[, borderType ]]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6aabeed-6c0d-4b8c-b3c7-02085e319038",
   "metadata": {},
   "source": [
    "##### 영상 src에 가우시안 필터링하고 dstsize에 주어진 크기로 dst에 확대한다.\n",
    "##### default는 가로, 세로 각각을 2배 크기로 확대한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110d1745-97dd-473e-800d-0bf0b1c8cd3d",
   "metadata": {},
   "source": [
    "- cv2.pyrMeanShiftFiltering(src, sp, sr[, dst[, maxLevel[, termcrit ]]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abf1d14-1b23-4a0a-9227-071e436d9b0a",
   "metadata": {},
   "source": [
    "##### 영상 src에서 피라미드 기반 평균이동 필터링을 수행한다.\n",
    "##### 입력 영상 src는 8비트 3채널 컬러 영상이고, dst는 src와 자료형과 크기가 같은 결과 영상으로, 평균이동 알고리즘에 의해 유사한 컬러 값을 갖는 화소가 같은 값을 갖는다.\n",
    "##### termcrit는 반복의 종료조건을 최대 반복 횟수 cv2.TERM_CRITERIA_MAX_ITER 또는 cv2.TERM_CRITERIA_COUNT와 오차 cv2.TERM_CRITERIA_EPS로 설정한다.\n",
    "##### sp >= 1 는 공간 윈도우의 반지름, sr은 컬러 윈도우의 반지름, maxLevel은 피라미드의 최대 레벨이다.\n",
    "##### src의 화소(X, Y)에 대하여, 공간 윈도우와 컬러 윈도우를 사용하여 반복적으로 meanshift를 수행한다.\n",
    "##### (x, y)는 공간 윈도우 내의 이웃 좌표이다. RGB, HSV 컬러 모델 등 3-개의 요소를 갖는 컬러 모델이면 모두 가능하다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d696cac0-6772-4f77-80c1-de1ce5a426b7",
   "metadata": {},
   "source": [
    "#### 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6281ce20-2ae3-4f24-9cb2-143538cc34fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src.shape= (512, 512, 3)\n",
      "down2.shape= (256, 256, 3)\n",
      "down4.shape= (128, 128, 3)\n",
      "up2.shape= (1024, 1024, 3)\n",
      "up4.shape= (2048, 2048, 3)\n"
     ]
    }
   ],
   "source": [
    "# 0712.py\n",
    "import cv2\n",
    "import numpy as np\n",
    "#1\n",
    "src = cv2.imread('./data/lena.jpg')\n",
    "\n",
    "down2 = cv2.pyrDown(src)\n",
    "down4 = cv2.pyrDown(down2)\n",
    "print('src.shape=', src.shape)\n",
    "print('down2.shape=', down2.shape)\n",
    "print('down4.shape=', down4.shape)\n",
    "\n",
    "#2\n",
    "up2 = cv2.pyrUp(src)\n",
    "up4 = cv2.pyrUp(up2)\n",
    "print('up2.shape=', up2.shape)\n",
    "print('up4.shape=', up4.shape)\n",
    "\n",
    "cv2.imshow('down2',down2)\n",
    "## cv2.imshow('down4',down4)\n",
    "cv2.imshow('up2',up2)\n",
    "## cv2.imshow('up4',up4)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2361bb57-1e7c-41d5-b91c-9f6bfb758c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "## cv2.pyrMeanShiftFiltering()영역 검출\n",
    "# 0713.py\n",
    "import cv2\n",
    "import numpy as np\n",
    "#1\n",
    "def floodFillPostProcess(src, diff=(2,2,2)):\n",
    "    img = src.copy()\n",
    "    rows, cols = img.shape[:2]\n",
    "    mask   = np.zeros(shape=(rows+2, cols+2), dtype=np.uint8)\n",
    "    for y in range(rows):\n",
    "        for x in range(cols):\n",
    "            if mask[y+1, x+1] == 0:\n",
    "                r = np.random.randint(256)\n",
    "                g = np.random.randint(256)\n",
    "                b = np.random.randint(256)\n",
    "                cv2.floodFill(img,mask,(x,y),(b,g,r),diff,diff)\n",
    "    return img\n",
    "# floodFillPostProcess()는 cv2.floodFill() 함수를 사용하여 src를 복사한 img 영상에서 유사한 영역을 채워 분할한다.\n",
    "# mask는 img보다 가로, 세로로 2만큼 큰 영상이고, 0인 화소, (x, y)를 찾아, cv2.floodFill()로 채우면, (x, y)의 화소값과 위아래로 diff 차이가 나지 않으면 img의\n",
    "# 해당 화소는 newVal로 채우고, mask는 1로 채운다.\n",
    "\n",
    "#2\n",
    "src = cv2.imread('./data/flower.jpg')\n",
    "hsv = cv2.cvtColor(src, cv2.COLOR_BGR2HSV)\n",
    "dst  = floodFillPostProcess(src)\n",
    "dst2 = floodFillPostProcess(hsv)\n",
    "cv2.imshow('src',src)\n",
    "cv2.imshow('hsv',hsv)\n",
    "cv2.imshow('dst',dst)\n",
    "cv2.imshow('dst2',dst2)\n",
    "# BGR입력 영상 src를 HSV영상 hsv로 변환한다.\n",
    "# floodFillPostProcess()를 src, hsv에 적용하여 각각 dst, dst2로 영역 분할한다.\n",
    "# 필터링하지 않은 src, hsv 영상에서 디폴트 차이 diff = (2, 2, 2)에 의한 채우기로 영역 분할한 결과는 매우 많은 영역이 검출된다.\n",
    "\n",
    "#3\n",
    "res = cv2.pyrMeanShiftFiltering(src, sp=5, sr=20, maxLevel=4)\n",
    "dst3 = floodFillPostProcess(res)\n",
    "# cv2.pyrMeanShiftFiltering()로 src를 sp = 5, sr = 20, maxLevel = 4로 피라미드 평균이동 필터링하여 res에 저장한다.\n",
    "# floodFillPostProcess()를 res에 적용하여 dst으로 영역 분할한다.\n",
    "\n",
    "#4\n",
    "term_crit=(cv2.TERM_CRITERIA_EPS+cv2.TERM_CRITERIA_MAX_ITER, 10, 2)\n",
    "res2=cv2.pyrMeanShiftFiltering(hsv,sp=5,sr=20,maxLevel=4, termcrit=term_crit)\n",
    "dst4 = floodFillPostProcess(res2)\n",
    "# cv2.pyMeanShiftFiltering()로 hsv를 sp = 5, sr = 20, maxLevel = 4, 최대반복횟수 = 10, 오차 2의 종료 조건을 적용하여 피라미드 평균 이동 필터링하여 res2에 저장\n",
    "# floodFillPostProcess()를 res2에 적용하여 dst4로 영역 분할한다. 피라미드 필터를 적용한 결과의 영역 분할 결과는 좀 더 큰 영역으로 분할한다.\n",
    "\n",
    "cv2.imshow('res',res)\n",
    "cv2.imshow('res2',res2)\n",
    "cv2.imshow('dst3',dst3)\n",
    "cv2.imshow('dst4',dst4)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0d12f1-ec9f-40c2-8bca-ea1adbbab5e8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### K-Means 클러스터링 분할"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75fb7cd-0746-4952-84f7-78e4d3c15f0f",
   "metadata": {},
   "source": [
    "* K-Means 클러스터링 알고리즘\n",
    "    * 단계 1\n",
    "    - 클러스터 개수 k를 고정하고, t = 0으로 초기화한다. K개의 클러스터 C<sup>0</sup><sub>i</sub>, i = 1, ..., K의 평균 m<sup>0</sup><sub>i</sub>, i = 1, ...,K을 임의로 선택한다.\n",
    "    * 단계 2\n",
    "    - 클러스터링하려는 데이터 x<sub>j</sub>, j = 1, ..., M 각각에 K개의 클러스터 평균과의 최소거리가 되는 클러스터 C<sup>t</sup><sub>p</sub>로 x<sub>j</sub>을 분류한다.\n",
    "    * 단계 3\n",
    "    - 각 클러스터 C<sup>t</sup><sub>i</sub>, i = 1, ..., K에 속한 데이터를 이용하여 새로운 클러스터 평균 m<sub>i</sub><sup>t+1</sup>, i = 1, ..., K를 계산한다.\n",
    "    * 단계 4\n",
    "    - t = t + 1로 증가시키고, 만약 t > MAX_ITER 또는 err = Σ|m<sub>i</sub><sup>t+1</sup> - m<sub>i</sub><sup>t+1</sup>| < EPS이면 중지하고, 그렇지 않으면 단계 2, 단계 3을 반복한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445be894-21da-42d2-a56e-1848c6c4fdd5",
   "metadata": {},
   "source": [
    "- cv2.kmeans(data, K, bestLabels, criteria, attempts, flags[, centers ]) -> retval, bestlabels, centers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd7a69f-589b-43b6-9e8b-579f5ffe6441",
   "metadata": {},
   "source": [
    "##### data는 클러스터링을 위한 데이터이다. 각 샘플 데이터는 data의 행에 저장된다. K는 클러스터의 개수이고, bestLabels는 각 샘플의 클러스터 번호를 labels에 저장한다.\n",
    "##### criteria는 종료조건으로 최대 반복회수와 각 클러스터의 중심이 오차 이내로 움직이면 종료한다. cv2.TERM_CRITERIA_MAX_ITER 또는 cv2.TERM_CRITERIA_COUNT와 오차 cv2.TERM_CRITERIA_EPS로 설정한다.\n",
    "##### attempts는 알고리즘을 시도하는 횟수로, 서로 다른 시도 횟수 중 최적의 레이블링 결과를 bestLabels에 저장하여 반환한다. centers는 클러스터의 중심을 각 행에 저장하여 반환한다.\n",
    "##### flags는 K 개의 클러스터 중심을 초기화하는 방법을 명시한다. cv2.KMEANS_RANDOM_CENTERS이면 난수를 사용하여 임의로 설정한다. cv2.KMEANS_PP_CENTERS이면 Arthur and Vassilvitskii에 의해 제안 방법을 사용한다. cv2.KMEANS_USE_INITIAL_LABELS이면, 처음 시도에서는 사용자가 제공한 레이블을 사용하고, 다음 시도부터는 난수를 이용하여 임의로 설정한다.\n",
    "##### 클러스터링 밀집도를 계산하여 retval에 반환한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608839ba-9254-4209-9240-3323bce27909",
   "metadata": {},
   "source": [
    "#### 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f3db2e2-1337-4c8d-899f-ed987c72cfd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "centers.shape= (2, 3)\n",
      "labels.shape= (261120, 1)\n",
      "ret= 1274532890.7591445\n",
      "labels2.max()= 1\n"
     ]
    }
   ],
   "source": [
    "## cv2.kmeans() 컬러 클러스터링 영역 검출\n",
    "# 0714.py\n",
    "import cv2\n",
    "import numpy as np\n",
    "#1\n",
    "# src = cv2.imread('./data/hand.jpg')\n",
    "src = cv2.imread('./data/flower.jpg')\n",
    "hsv = cv2.cvtColor(src, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# data = src.reshape((-1,3)).astype(np.float32) # BGR 클러스터링\n",
    "data = hsv.reshape((-1,3)).astype(np.float32) # HSV 클러스터링\n",
    "# 컬러 입력 영상 src를 HSV 컬러 영상 hsv로 변환한다. 입력 영상 src 또는 hsv의 각 화소의 컬러가 data의 행에 배치되도록 모양을 변환한다.\n",
    "# data.shape = (230400, 3)이다.\n",
    "\n",
    "#2\n",
    "K = 2\n",
    "term_crit=(cv2.TERM_CRITERIA_EPS+cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
    "ret, labels, centers = cv2.kmeans(data, K, None, term_crit, 5,\n",
    "                                  cv2.KMEANS_RANDOM_CENTERS)\n",
    "print('centers.shape=', centers.shape)\n",
    "print('labels.shape=', labels.shape)\n",
    "print('ret=', ret)\n",
    "# cv2.kmeans()로 'hand.jpg'는 K = 2, 'SegmentTest.jpg'는 K = 5로 클러스터링 한다.\n",
    "# centers.shape = (2, 3)로 centers에 K개의 클러스터 중심점을 반환한다. labels.shape = (230400, 1)로 labels는 각 데이터 점의 클러스터 번호를 반환한다.\n",
    "# ret는 클러스터 응집도를 반환한다.\n",
    "\n",
    "#3\n",
    "centers = np.uint8(centers)\n",
    "res   = centers[labels.flatten()]\n",
    "dst  = res.reshape(src.shape)\n",
    "\n",
    "labels2 = np.uint8(labels.reshape(src.shape[:2]))\n",
    "print('labels2.max()=', labels2.max())\n",
    "dst   = np.zeros(src.shape, dtype=src.dtype)\n",
    "for i in range(K): # 분할영역 표시\n",
    "    r = np.random.randint(256)\n",
    "    g = np.random.randint(256)\n",
    "    b = np.random.randint(256)\n",
    "    dst[labels2 == i] = [b, g, r]\n",
    "\n",
    "# centers를 np.uint8 자료형으로 변환하고, res = centers[labels.flatten()]로 res에 레이블에 대한 클러스터 중심으로 변환한 res를 생성한다. res.shape = (230400, 3)이다.\n",
    "# res를 src와 같은 영상 모양으로 변환한다. 주석 처리 부분은 label2의 각 클러스터 번호에 난수로 생성한 컬러를 지정하여 dst 영상을 생성한다.\n",
    "    \n",
    "cv2.imshow('dst',dst)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c8976f-c42b-41b0-9b41-c1a30a019080",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 연결 요소 검출"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb9d091-962b-4928-93c8-462073e6b4ae",
   "metadata": {},
   "source": [
    "- cv2.connectedComponents(image[, labels[, connectivity[, ltype]]]) -> retval, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7f76ee-5179-422a-8b0f-d71985e7414c",
   "metadata": {},
   "source": [
    "##### image, 8비트 1-채널 입력 영상이다. labels는 연결 요소 정보를 갖는 입력 영상과 같은 크기의 출력 레이블이다.\n",
    "##### connectivity는 화소의 이웃 연결성으로 4 또는 8이다. Itype은 출력 labels의 자료형으로 cv2.CV_32S 또는 cv2.CV_16U이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17973cde-c53f-4f64-9407-9658993bb9f2",
   "metadata": {},
   "source": [
    "- cv2.connectedComponentsWithStats(image[, labels[, stats[, centroids[, connectivity[, ltype]]]]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2acdee-85d9-45e9-ab71-611041ad7d8e",
   "metadata": {},
   "source": [
    "##### image는 8비트 1-채널 입력 영상이다. labels는 연결 요소 정보를 갖는 입력 영상과 같은 크기의 출력 레이블이다.\n",
    "##### stats는 각 레이블에 대해 5열에 바운딩 사각형의 (left, top, width, height, area) 통계정보를 갖는다. 0행은 배경 레이블 정보이다.\n",
    "##### centroids는 각 레이블의 중심좌표이다.\n",
    "##### connectivity는 화소의 이웃 연결성으로 4 또는 8이다. ltype은 출력 labels의 자료형으로 cv2.CV_32S 또는 cv2.CV_16U이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d879a302-1840-420b-a98a-f609aa41b201",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4bca52da-be82-463a-9f27-2d53a65ee906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ret= 4\n"
     ]
    }
   ],
   "source": [
    "## 레이블링 1(임계값 이진 영상): cv2.connectedComponents()\n",
    "# 0715.py\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "#1\n",
    "src = cv2.imread('./data/circles.jpg')\n",
    "gray = cv2.cvtColor(src,cv2.COLOR_BGR2GRAY)\n",
    "ret, res = cv2.threshold(gray, 128, 255, cv2.THRESH_BINARY_INV)\n",
    "# 컬러 입력 영상 src를 그레이스케일 영상 gray로 변환한다. 입력 영상에서 원이 검은색, 배경이 흰색이어서 cv2.THRESH_BINARY_INV로 입계값 128을 적용하여 이진영상 생성\n",
    "\n",
    "#2\n",
    "ret, labels = cv2.connectedComponents(res)\n",
    "print('ret=', ret)\n",
    "# cv2.connectedComponents()로 이진영상 res를 레이블링하여 레이블 개수는 배경을 포함하여 ret = 4이고, 레이블정보 labels를 생성한다.\n",
    "# 검출된 원의 개수 ret - 1이다.\n",
    "\n",
    "#3\n",
    "dst   = np.zeros(src.shape, dtype=src.dtype)\n",
    "for i in range(1, ret): # 분할영역 표시\n",
    "    r = np.random.randint(256)\n",
    "    g = np.random.randint(256)\n",
    "    b = np.random.randint(256)\n",
    "    dst[labels == i] = [b, g, r]\n",
    "# labels에서 배경 레이블(0)은 제외하고, 1에서부터 ret - 1까지의 레이블 영역을 난수로 생성한 같은 컬러로 지정하여 dst영상을 생성한다.\n",
    "\n",
    "cv2.imshow('res',  res)\n",
    "cv2.imshow('dst',  dst) \n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6503d746-77f8-4a28-b181-4bd7d4b2986d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ret = 4\n",
      "stats = [[     0      0    512    512 222719]\n",
      " [   308     86    125    125  12281]\n",
      " [   153    145    152    152  18152]\n",
      " [   292    338    107    107   8992]]\n",
      "centroids = [[247.77339607 258.80937863]\n",
      " [370.         148.        ]\n",
      " [228.5        220.50534376]\n",
      " [345.00077847 390.99477313]]\n"
     ]
    }
   ],
   "source": [
    "# 0716.py\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "#1\n",
    "src = cv2.imread('./data/circles.jpg')\n",
    "gray = cv2.cvtColor(src,cv2.COLOR_BGR2GRAY)\n",
    "ret, res = cv2.threshold(gray, 128, 255, cv2.THRESH_BINARY_INV)\n",
    "# 컬러 입력 영상 src를 그레이스케일 영상 gray로 변환한다. cv2.THRESH_BINARY_INV로 임계값 128을 적용하여 이진영상 res를 생성한다.\n",
    "\n",
    "#2\n",
    "ret, labels, stats, centroids = cv2.connectedComponentsWithStats(res)\n",
    "print('ret =', ret)\n",
    "print('stats =', stats)\n",
    "print('centroids =', centroids)\n",
    "# cv2.connectedComponentsWithStats()로 이진 영상 res를 레이블링하여 레이블 개수 ret, 레이블 정보 labels, 통계정보 stats, 중심점 centroids를 계산한다.\n",
    "\n",
    "#3\n",
    "dst   = np.zeros(src.shape, dtype=src.dtype)\n",
    "for i in range(1, int(ret)): # 분할영역 표시\n",
    "    r = np.random.randint(256)\n",
    "    g = np.random.randint(256)\n",
    "    b = np.random.randint(256)\n",
    "    dst[labels == i] = [b, g, r]\n",
    "# labels에서 배경 레이블(0)은 제외하고, 1에서부터 ret -1 까지의 레이블 영역을 난수로 생성한 같은 컬러로 채운다.\n",
    "\n",
    "#4    \n",
    "for i in range(1, int(ret)):\n",
    "    x, y, width, height, area = stats[i]\n",
    "    cv2.rectangle(dst, (x,y), (x+width, y+height), (0, 0, 255), 2)\n",
    "\n",
    "    cx, cy = centroids[i]\n",
    "    cv2.circle(dst, (int(cx), int(cy)), 5, (255,0,0), -1)\n",
    "# 레이블 i의 통계정보 stats[i]를 이용하여 바운딩 빨간색으로 사각형을 그리고, 중심점 centroids[i]를 이용하여 파란색으로 원을 그린다.\n",
    "\n",
    "cv2.imshow('src',  src)\n",
    "cv2.imshow('dst',  dst) \n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
